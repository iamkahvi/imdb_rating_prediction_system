{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "https://machinelearningmastery.com/neural-network-models-for-combined-classification-and-regression/"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Dense\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\r\n",
    "\r\n",
    "pd.options.mode.chained_assignment = None #remove setting with copy warning\r\n",
    "\r\n",
    "dfMovies = pd.read_csv('data/IMDb movies.csv', dtype={\"year\": str})\r\n",
    "dfNames = pd.read_csv('data/IMDb names.csv')\r\n",
    "dfRatings = pd.read_csv('data/IMDb ratings.csv')\r\n",
    "dfTitlePrincipals = pd.read_csv('data/IMDb title_principals.csv')\r\n",
    "\r\n",
    "# just run this cell once to load data into memory\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from tensorflow.keras.utils import to_categorical\r\n",
    "import keras\r\n",
    "# dfMovies = dfMovies[['imdb_title_id', 'title', 'year','genre', 'duration', 'country', 'language', 'director', 'writer', 'production_company', 'budget', 'worlwide_gross_income']]\r\n",
    "# dfNames = dfNames[['imdb_name_id', 'name']]\r\n",
    "# dfRatings = dfRatings[['imdb_title_id', 'weighted_average_vote', 'total_votes', 'mean_vote' ]] # come back to this and include age groups/male/female votes\r\n",
    "# dfTitlePrincipals = dfTitlePrincipals[['imdb_title_id', 'ordering', 'imdb_name_id']] # shouyld we get category? \"actress\"/\"actor\" (dont know if its necessary)\r\n",
    "\r\n",
    "\r\n",
    "#one hot encode into top 10 features\"\r\n",
    "# country, language, director, writer, produciton_company, actor names\r\n",
    "\r\n",
    "dfMovies = dfMovies[['imdb_title_id', 'year','duration', 'worlwide_gross_income', 'genre', 'language', 'country']]\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "oneHotGenres = dfMovies['genre'].str.get_dummies(', ')\r\n",
    "oneHotCountries = dfMovies['country'].str.get_dummies(', ')\r\n",
    "oneHotLanguages = dfMovies['language'].str.get_dummies(', ')\r\n",
    "oneHotYears = dfMovies['year'].str.get_dummies() # one hot encoding of categorical features\r\n",
    "data = pd.concat([dfMovies, oneHotGenres,oneHotLanguages, oneHotCountries, oneHotYears], axis=1)\r\n",
    "dfRatings = dfRatings[['imdb_title_id', 'weighted_average_vote' ]] # come back to this and include age groups/male/female votes\r\n",
    "\r\n",
    "\r\n",
    "data = pd.merge(data, dfRatings, on=[\"imdb_title_id\"]) #@Jayden, this is sql equivalent inner join on imdb_title_id\r\n",
    "data = data.drop('imdb_title_id', axis=1)\r\n",
    "\r\n",
    "data = data.dropna()\r\n",
    "\r\n",
    "data['worlwide_gross_income'].replace(to_replace=r'^.*\\ ', value='', regex=True, inplace=True) # replace cells with vale of 0\r\n",
    "\r\n",
    "X = data.iloc[:, :-1]\r\n",
    "X.drop(['genre', 'language', 'country', 'year'], axis=1, inplace=True)\r\n",
    "y = data.iloc[:, -1]\r\n",
    "\r\n",
    "X = X.astype(float)\r\n",
    "y = y.astype(float)\r\n",
    "\r\n",
    "X = X.loc[:, ~X.columns.duplicated()]\r\n",
    "print(data.describe())\r\n",
    "\r\n",
    "\r\n",
    "X.to_csv('test.csv', index=False)\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "           duration        Action    Adult     Adventure     Animation  \\\n",
      "count  30856.000000  30856.000000  30856.0  30856.000000  30856.000000   \n",
      "mean     105.279654      0.159645      0.0      0.098393      0.042844   \n",
      "std       20.429065      0.366282      0.0      0.297849      0.202509   \n",
      "min       41.000000      0.000000      0.0      0.000000      0.000000   \n",
      "25%       92.000000      0.000000      0.0      0.000000      0.000000   \n",
      "50%      101.000000      0.000000      0.0      0.000000      0.000000   \n",
      "75%      114.000000      0.000000      0.0      0.000000      0.000000   \n",
      "max      808.000000      1.000000      0.0      1.000000      1.000000   \n",
      "\n",
      "          Biography       Comedy         Crime   Documentary         Drama  \\\n",
      "count  30856.000000  30856.00000  30856.000000  30856.000000  30856.000000   \n",
      "mean       0.043330      0.38926      0.133912      0.000032      0.587503   \n",
      "std        0.203603      0.48759      0.340564      0.005693      0.492292   \n",
      "min        0.000000      0.00000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.00000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.00000      0.000000      0.000000      1.000000   \n",
      "75%        0.000000      1.00000      0.000000      0.000000      1.000000   \n",
      "max        1.000000      1.00000      1.000000      1.000000      1.000000   \n",
      "\n",
      "       ...          2013          2014          2015          2016  \\\n",
      "count  ...  30856.000000  30856.000000  30856.000000  30856.000000   \n",
      "mean   ...      0.045567      0.045599      0.047511      0.051595   \n",
      "std    ...      0.208546      0.208617      0.212733      0.221211   \n",
      "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "               2017          2018          2019          2020  TV Movie 2019  \\\n",
      "count  30856.000000  30856.000000  30856.000000  30856.000000        30856.0   \n",
      "mean       0.055678      0.055646      0.047511      0.008848            0.0   \n",
      "std        0.229303      0.229240      0.212733      0.093646            0.0   \n",
      "min        0.000000      0.000000      0.000000      0.000000            0.0   \n",
      "25%        0.000000      0.000000      0.000000      0.000000            0.0   \n",
      "50%        0.000000      0.000000      0.000000      0.000000            0.0   \n",
      "75%        0.000000      0.000000      0.000000      0.000000            0.0   \n",
      "max        1.000000      1.000000      1.000000      1.000000            0.0   \n",
      "\n",
      "       weighted_average_vote  \n",
      "count           30856.000000  \n",
      "mean                6.096228  \n",
      "std                 1.092614  \n",
      "min                 1.000000  \n",
      "25%                 5.500000  \n",
      "50%                 6.200000  \n",
      "75%                 6.800000  \n",
      "max                 9.300000  \n",
      "\n",
      "[8 rows x 601 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# define the keras model\r\n",
    "model = Sequential()\r\n",
    "model.add(Dense(784, input_dim=X.shape[1], activation='relu', kernel_initializer='he_normal'))\r\n",
    "model.add(Dense(128, activation='sigmoid', kernel_initializer='he_normal'))\r\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal'))\r\n",
    "model.add(Dense(1, activation='linear'))\r\n",
    "\r\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae'])\r\n",
    "\r\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=784)\r\n",
    "\r\n",
    "\r\n",
    "yhat = model.predict(X_test)\r\n",
    "error = mean_absolute_error(y_test, yhat)\r\n",
    "print('MAE: %.3f' % error)\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 11.9577 - mse: 11.9577 - mae: 3.1158\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 2.2117 - mse: 2.2117 - mae: 1.2531\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 1.2305 - mse: 1.2305 - mae: 0.8440\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 1.2708 - mse: 1.2708 - mae: 0.8445\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 1.1875 - mse: 1.1875 - mae: 0.8376\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 1.1944 - mse: 1.1944 - mae: 0.8524\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 1.1867 - mse: 1.1867 - mae: 0.8443\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 1.1851 - mse: 1.1851 - mae: 0.8368\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 1.1854 - mse: 1.1854 - mae: 0.8384\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 1.1846 - mse: 1.1846 - mae: 0.8393\n",
      "MAE: 0.843\n",
      "[6.0871296]\n",
      "6.3\n",
      "[[6.087129]]\n",
      "       duration  worlwide_gross_income  Action  Adult  Adventure  Animation  \\\n",
      "76327      94.0               202788.0     0.0    0.0        0.0        0.0   \n",
      "\n",
      "       Biography  Comedy  Crime  Documentary  ...  2012  2013  2014  2015  \\\n",
      "76327        0.0     1.0    0.0          0.0  ...   0.0   0.0   0.0   0.0   \n",
      "\n",
      "       2016  2017  2018  2019  2020  TV Movie 2019  \n",
      "76327   0.0   1.0   0.0   0.0   0.0            0.0  \n",
      "\n",
      "[1 rows x 601 columns]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}